{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "279c375a",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import libraries for PDF parsing, NLP, knowledge graph construction, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd3ace7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m5 packages\u001b[0m \u001b[2min 34ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install PyPDF2 spacy networkx matplotlib scipy\n",
    "\n",
    "import PyPDF2\n",
    "import spacy\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import scipy\n",
    "from pyvis.network import Network\n",
    "import tempfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ac50375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download spaCy model only if not already installed\n",
    "import spacy.util\n",
    "model_name = 'en_core_web_sm'\n",
    "if not spacy.util.is_package(model_name):\n",
    "    import subprocess\n",
    "    subprocess.run(['python', '-m', 'spacy', 'download', model_name], check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c91e73",
   "metadata": {},
   "source": [
    "# Parse PDF to Extract Text\n",
    "Load a research paper PDF and extract its text content using PyPDF2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8c51d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Review, , pp. 1–8\n",
      "doi:\n",
      "Transfer learning improves performance in volumetric\n",
      "electron microscopy organelle segmentation across\n",
      "tissues\n",
      "Ronald Xie,1,2,3,Ben Mulcahy,4Ali Darbandi,4Sagar Marwah,4Fez Ali,1Yuna Lee,1\n",
      "Gunes Parlakgul,5Gokhan Hotamisligil,6,7Bo Wang,2,8,11,12,Sonya MacParland,8,9\n",
      "Mei Zhen3,4and Gary D. Bader1,3,4,12,13\n",
      "1The Donnelly Centre, University of Toronto, Toronto, Ontario, Canada,2Peter Munk Cardiac Centre and Joint Department of Medical\n",
      "Imaging, University Health Network, Toronto, Canada,3Department of Molecular Genetics, University of Toronto, Toronto, Ontario,\n",
      "Canada,4Lunenfeld-Tanenbaum Research Institute, Mount Sinai Hospital, Toronto, Ontario, Canada,5University of California, Berkeley,\n",
      "Berkeley, CA, USA,6Sabri ¨Ulker Center of Metabolic Research and Department of Molecular Metabolism, Harvard T.H. Chan School of\n",
      "Public Health, Boston, MA, USA,7Broad Institute of MIT and Harvard, Cambridge, MA, USA,8Department of Laboratory Medicine and\n",
      "Pathobiology, Temerty \n"
     ]
    }
   ],
   "source": [
    "# Extract text from PDF\n",
    "pdf_path = 'pdfs/zhen1.pdf'  # Change to your PDF file path\n",
    "text = ''\n",
    "with open(pdf_path, 'rb') as file:\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() or ''\n",
    "\n",
    "print(text[:1000])  # Preview the first 1000 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa92dc7",
   "metadata": {},
   "source": [
    "# Extract Concepts from Text\n",
    "Use spaCy to identify and extract key concepts (noun phrases and named entities) from the extracted text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd16d047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 192 high-level concepts. Sample: ['University Health Network', 'Jody Clements', 'Klaus H Maier-Hein', 'Huxley K Hoffman', 'Jurgen AW Heymann', 'Rajeev Parvathala', 'Rand Init', 'mouse cortex', 'Toronto General\\nResearch Institute', 'Peter Li']\n"
     ]
    }
   ],
   "source": [
    "# Extract concepts using spaCy with improved filtering for high-level concepts\n",
    "import string\n",
    "from collections import Counter\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(text)\n",
    "\n",
    "# Helper function to check if a phrase is high-level\n",
    "def is_high_level(phrase):\n",
    "    words = [w for w in phrase.split() if w.lower() not in STOP_WORDS and w not in string.punctuation]\n",
    "    # At least 2 words, not all stopwords, not too short\n",
    "    return len(words) >= 2 and len(phrase) > 6\n",
    "\n",
    "# Extract noun phrases and named entities\n",
    "candidates = []\n",
    "for np in doc.noun_chunks:\n",
    "    if is_high_level(np.text.strip()):\n",
    "        candidates.append(np.text.strip())\n",
    "for ent in doc.ents:\n",
    "    if is_high_level(ent.text.strip()):\n",
    "        candidates.append(ent.text.strip())\n",
    "\n",
    "# Count frequency and keep only those that appear more than once\n",
    "concept_counts = Counter(candidates)\n",
    "concepts = set([c for c, count in concept_counts.items() if count > 1])\n",
    "\n",
    "print(f\"Extracted {len(concepts)} high-level concepts. Sample:\", list(concepts)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6873adfc",
   "metadata": {},
   "source": [
    "# Build Knowledge Graph\n",
    "Construct a knowledge graph where nodes are concepts and edges represent co-occurrence within the same sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1082ac6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph has 192 nodes and 472 edges.\n"
     ]
    }
   ],
   "source": [
    "# Build knowledge graph from concept co-occurrence in sentences\n",
    "graph = nx.Graph()\n",
    "graph.add_nodes_from(concepts)\n",
    "\n",
    "# Add edges based on co-occurrence in sentences\n",
    "for sent in doc.sents:\n",
    "    sent_concepts = set()\n",
    "    for np in sent.noun_chunks:\n",
    "        if np.text.strip() in concepts:\n",
    "            sent_concepts.add(np.text.strip())\n",
    "    for ent in sent.ents:\n",
    "        if ent.text.strip() in concepts:\n",
    "            sent_concepts.add(ent.text.strip())\n",
    "    # Add edges between all pairs of concepts in the sentence\n",
    "    for c1 in sent_concepts:\n",
    "        for c2 in sent_concepts:\n",
    "            if c1 != c2:\n",
    "                graph.add_edge(c1, c2)\n",
    "\n",
    "print(f\"Graph has {graph.number_of_nodes()} nodes and {graph.number_of_edges()} edges.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a858c3",
   "metadata": {},
   "source": [
    "# Visualize Knowledge Graph\n",
    "Visualize the constructed knowledge graph using NetworkX and Matplotlib (non-interactive visualization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67b316e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "knowledge_graph.html\n",
      "Interactive knowledge graph saved to knowledge_graph.html\n"
     ]
    }
   ],
   "source": [
    "# Visualize the knowledge graph interactively with PyVis (save HTML only, improved readability)\n",
    "from pyvis.network import Network\n",
    "\n",
    "# Create a PyVis network with larger node and font sizes\n",
    "net = Network(height='800px', width='100%', notebook=True, bgcolor='#ffffff', font_color='black')\n",
    "net.barnes_hut()\n",
    "\n",
    "# Add nodes and edges with larger size and font\n",
    "for node in graph.nodes():\n",
    "    net.add_node(node, label=node, size=30, font={\"size\": 28})\n",
    "for source, target in graph.edges():\n",
    "    net.add_edge(source, target)\n",
    "\n",
    "# Set physics options for a tighter layout and better initial zoom\n",
    "net.set_options('''\n",
    "var options = {\n",
    "  \"nodes\": {\n",
    "    \"font\": {\"size\": 28},\n",
    "    \"size\": 30\n",
    "  },\n",
    "  \"edges\": {\n",
    "    \"color\": {\"inherit\": true},\n",
    "    \"smooth\": false\n",
    "  },\n",
    "  \"physics\": {\n",
    "    \"barnesHut\": {\n",
    "      \"gravitationalConstant\": -20000,\n",
    "      \"centralGravity\": 0.5,\n",
    "      \"springLength\": 150,\n",
    "      \"springConstant\": 0.04,\n",
    "      \"damping\": 0.09,\n",
    "      \"avoidOverlap\": 1\n",
    "    },\n",
    "    \"minVelocity\": 0.75\n",
    "  }\n",
    "}\n",
    "''')\n",
    "\n",
    "# Save to HTML file (you can open this file outside Jupyter)\n",
    "output_path = 'knowledge_graph.html'\n",
    "net.show(output_path)\n",
    "print(f\"Interactive knowledge graph saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
