{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "279c375a",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import libraries for PDF parsing, NLP, knowledge graph construction, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bd3ace7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m7 packages\u001b[0m \u001b[2min 56ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install PyPDF2 spacy networkx matplotlib scipy openai python-dotenv\n",
    "\n",
    "import PyPDF2\n",
    "import spacy\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import scipy\n",
    "from pyvis.network import Network\n",
    "import tempfile\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5ac50375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download spaCy model only if not already installed\n",
    "import spacy.util\n",
    "model_name = 'en_core_web_sm'\n",
    "if not spacy.util.is_package(model_name):\n",
    "    import subprocess\n",
    "    subprocess.run(['python', '-m', 'spacy', 'download', model_name], check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c91e73",
   "metadata": {},
   "source": [
    "# Parse PDF to Extract Text\n",
    "Load a research paper PDF and extract its text content using PyPDF2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c51d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL RESEARCH\n",
      "published: 14 September 2021\n",
      "doi: 10.3389/fpsyg.2021.751492\n",
      "Frontiers in Psychology | www.frontiersin.org 1 September 2021 | Volume 12 | Article 751492Editedby:\n",
      "XiyingLi,\n",
      "ShaanxiNormalUniversity,China\n",
      "Reviewedby:\n",
      "YanDong,\n",
      "BeijingNormalUniversity,China\n",
      "ZhiqiangMa,\n",
      "JiangnanUniversity,China\n",
      "XiaofeiQi,\n",
      "DurhamUniversity,UnitedKingdom\n",
      "*Correspondence:\n",
      "JunyiLi\n",
      "junyili@sicnu.edu.cn\n",
      "XuechenDing\n",
      "dingxuechen_psy@163.com\n",
      "Specialtysection:\n",
      "Thisarticlewassubmittedto\n",
      "EducationalPsychology,\n",
      "asectionofthejournal\n",
      "FrontiersinPsychology\n",
      "Received: 01August2021\n",
      "Accepted: 11August2021\n",
      "Published: 14September2021\n",
      "Citation:\n",
      "WuC,LiJ,ZhangY,LanC,ZhouK,\n",
      "WangY,LuLandDingX(2021)Can\n",
      "MOOCInstructorBePortrayedby\n",
      "SemanticFeatures?UsingDiscourse\n",
      "andClusteringAnalysistoIdentify\n",
      "Lecture-StyleofInstructorsin\n",
      "MOOCs.Front.Psychol.12:751492.\n",
      "doi:10.3389/fpsyg.2021.751492Can MOOC Instructor Be Portrayed\n",
      "by Semantic Features? Using\n",
      "Discourse and Clustering Analysis to\n",
      "Identify Lecture-Style of Instructors\n",
      "in MO\n"
     ]
    }
   ],
   "source": [
    "# Extract text from PDF\n",
    "pdf_path = 'pdfs/mooc1.pdf'  # Change to your PDF file path\n",
    "text = ''\n",
    "with open(pdf_path, 'rb') as file:\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() or ''\n",
    "\n",
    "print(text[:1000])  # Preview the first 1000 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa92dc7",
   "metadata": {},
   "source": [
    "# Extract Concepts from Text\n",
    "Use spaCy to identify and extract key concepts (noun phrases and named entities) from the extracted text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cd16d047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 87 high-level concepts. Sample: ['deep learning models', 'C Shan Xu', 'Rand Init', 'Matija Marolt', 'transfer learning', 'Song Pang', 'an additional test', 'Toronto General\\nResearch Institute', 'Automatic segmentation', 'Constantin Pape']\n"
     ]
    }
   ],
   "source": [
    "# Extract concepts using spaCy with improved filtering for high-level concepts\n",
    "import string\n",
    "from collections import Counter\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(text)\n",
    "\n",
    "# Exclude these entity types\n",
    "EXCLUDE_ENT_TYPES = {\"PERSON\", \"DATE\", \"TIME\", \"PERCENT\", \"MONEY\", \"QUANTITY\", \"ORDINAL\", \"CARDINAL\"}\n",
    "\n",
    "# Helper function to check if a phrase is a high-level concept\n",
    "def is_high_level(phrase, ent_type=None):\n",
    "    words = [w for w in phrase.split() if w.lower() not in STOP_WORDS and w not in string.punctuation]\n",
    "    # At least 2 words, not all stopwords, not too short\n",
    "    if len(words) < 2 or len(phrase) <= 6:\n",
    "        return False\n",
    "    if ent_type and ent_type in EXCLUDE_ENT_TYPES:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Extract noun phrases and named entities (excluding irrelevant types)\n",
    "candidates = []\n",
    "for np in doc.noun_chunks:\n",
    "    if is_high_level(np.text.strip()):\n",
    "        candidates.append(np.text.strip())\n",
    "for ent in doc.ents:\n",
    "    if is_high_level(ent.text.strip(), ent.label_):\n",
    "        candidates.append(ent.text.strip())\n",
    "\n",
    "# Count frequency and keep only those that appear more than once\n",
    "concept_counts = Counter(candidates)\n",
    "concepts = set([c for c, count in concept_counts.items() if count > 1])\n",
    "\n",
    "print(f\"Extracted {len(concepts)} high-level concepts. Sample:\", list(concepts)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6873adfc",
   "metadata": {},
   "source": [
    "# Build Knowledge Graph\n",
    "Construct a knowledge graph where nodes are concepts and edges represent co-occurrence within the same sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1082ac6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph has 87 nodes and 118 edges.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "graph = nx.Graph()\n",
    "graph.add_nodes_from(concepts)\n",
    "\n",
    "edge_contexts = defaultdict(list)\n",
    "for sent in doc.sents:\n",
    "    sent_concepts = set()\n",
    "    for np in sent.noun_chunks:\n",
    "        if np.text.strip() in concepts:\n",
    "            sent_concepts.add(np.text.strip())\n",
    "    for ent in sent.ents:\n",
    "        if ent.text.strip() in concepts:\n",
    "            sent_concepts.add(ent.text.strip())\n",
    "    # Add edges between all pairs of concepts in the sentence\n",
    "    for c1, c2 in itertools.combinations(sent_concepts, 2):\n",
    "        graph.add_edge(c1, c2)\n",
    "        edge_contexts[(c1, c2)].append(sent.text.strip())\n",
    "# Add context as edge attribute (join multiple sentences if needed)\n",
    "for (c1, c2), contexts in edge_contexts.items():\n",
    "    if graph.has_edge(c1, c2):\n",
    "        graph[c1][c2]['context'] = '\\n---\\n'.join(contexts)\n",
    "\n",
    "print(f\"Graph has {graph.number_of_nodes()} nodes and {graph.number_of_edges()} edges.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a858c3",
   "metadata": {},
   "source": [
    "# Visualize Knowledge Graph\n",
    "Visualize the constructed knowledge graph using NetworkX and Matplotlib (non-interactive visualization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "67b316e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "knowledge_graph.html\n",
      "Interactive knowledge graph saved to knowledge_graph.html\n"
     ]
    }
   ],
   "source": [
    "# Visualize the knowledge graph interactively with PyVis (save HTML only, improved readability)\n",
    "from pyvis.network import Network\n",
    "\n",
    "# Create a PyVis network with larger node and font sizes\n",
    "net = Network(height='800px', width='100%', notebook=True, bgcolor='#ffffff', font_color='black')\n",
    "net.barnes_hut()\n",
    "\n",
    "# Add nodes and edges with larger size and font\n",
    "for node in graph.nodes():\n",
    "    net.add_node(node, label=node, size=30, font={\"size\": 28})\n",
    "# Add edges with context as tooltip\n",
    "for source, target, data in graph.edges(data=True):\n",
    "    tooltip = data.get('context', '')\n",
    "    net.add_edge(source, target, title=tooltip)\n",
    "\n",
    "# Set physics options for a tighter layout and better initial zoom\n",
    "net.set_options('''\n",
    "var options = {\n",
    "  \"nodes\": {\n",
    "    \"font\": {\"size\": 28},\n",
    "    \"size\": 30\n",
    "  },\n",
    "  \"edges\": {\n",
    "    \"color\": {\"inherit\": true},\n",
    "    \"smooth\": false\n",
    "  },\n",
    "  \"physics\": {\n",
    "    \"barnesHut\": {\n",
    "      \"gravitationalConstant\": -20000,\n",
    "      \"centralGravity\": 0.5,\n",
    "      \"springLength\": 150,\n",
    "      \"springConstant\": 0.04,\n",
    "      \"damping\": 0.09,\n",
    "      \"avoidOverlap\": 1\n",
    "    },\n",
    "    \"minVelocity\": 0.75\n",
    "  }\n",
    "}\n",
    "''')\n",
    "\n",
    "# Save to HTML file (you can open this file outside Jupyter)\n",
    "output_path = 'knowledge_graph.html'\n",
    "net.show(output_path)\n",
    "print(f\"Interactive knowledge graph saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a4b810",
   "metadata": {},
   "source": [
    "# LLM-Based Concept and Relationship Extraction for Knowledge Graphs\n",
    "This workflow uses the OpenAI API to extract high-level concepts and their relationships from research text, then builds and visualizes a labeled knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "455f69f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 283 concept-relationship triples. Sample: [(\"'Volumetric electron microscopy'\", \"'enables'\", \"'nanoscale resolution three-dimensional imaging'\"), (\"'nanoscale resolution three-dimensional imaging'\", \"'used for'\", \"'biological samples'\"), (\"'Identification and labeling'\", \"'required for'\", \"'image interpretation'\"), (\"'manual labeling'\", \"'is'\", \"'time-consuming'\"), (\"'deep learning segmentation algorithms'\", \"'automate'\", \"'labeling'\")]\n"
     ]
    }
   ],
   "source": [
    "# Load OpenAI API key from .env\n",
    "load_dotenv()\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_KEY\")\n",
    "\n",
    "# Use the new OpenAI API client (openai>=1.0.0)\n",
    "client = openai.Client(api_key=OPENAI_KEY)\n",
    "\n",
    "# Function to chunk text into manageable pieces\n",
    "def chunk_text(text, max_tokens=1500):\n",
    "    paragraphs = text.split('\\n')\n",
    "    chunks = []\n",
    "    current = ''\n",
    "    for para in paragraphs:\n",
    "        if len(current) + len(para) < max_tokens:\n",
    "            current += para + '\\n'\n",
    "        else:\n",
    "            chunks.append(current)\n",
    "            current = para + '\\n'\n",
    "    if current:\n",
    "        chunks.append(current)\n",
    "    return chunks\n",
    "\n",
    "# Prompt for extracting concept triples\n",
    "PROMPT = (\n",
    "    \"Extract a list of the most important technical concepts and their relationships from the following text. \"\n",
    "    \"Return as a list of triples in the format (concept1, relationship, concept2). \"\n",
    "    \"Focus on high-level, domain-relevant concepts and meaningful relationships.\\n\\nText:\\n\"\n",
    ")\n",
    "\n",
    "def extract_triples_from_text(text):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": PROMPT + text}],\n",
    "        max_tokens=800,\n",
    "        temperature=0.2\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    # Extract triples using regex\n",
    "    triples = re.findall(r'\\(([^,]+),\\s*([^,]+),\\s*([^\\)]+)\\)', content)\n",
    "    return [tuple(map(str.strip, t)) for t in triples]\n",
    "\n",
    "# Chunk the text and extract triples\n",
    "chunks = chunk_text(text, max_tokens=1500)\n",
    "all_triples = []\n",
    "for chunk in chunks:\n",
    "    triples = extract_triples_from_text(chunk)\n",
    "    all_triples.extend(triples)\n",
    "\n",
    "print(f\"Extracted {len(all_triples)} concept-relationship triples. Sample:\", all_triples[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7082b62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph has 435 nodes and 280 edges.\n"
     ]
    }
   ],
   "source": [
    "# Build a labeled knowledge graph from triples\n",
    "G = nx.DiGraph()\n",
    "for c1, rel, c2 in all_triples:\n",
    "    G.add_node(c1)\n",
    "    G.add_node(c2)\n",
    "    G.add_edge(c1, c2, label=rel)\n",
    "print(f\"Graph has {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ac7d5195",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'community' has no attribute 'best_partition'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Cluster nodes using Louvain community detection (on undirected version)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcommunity\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcommunity_louvain\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m partition = \u001b[43mcommunity_louvain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbest_partition\u001b[49m(G.to_undirected()) \u001b[38;5;28;01mif\u001b[39;00m G.number_of_edges() > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m node, cluster \u001b[38;5;129;01min\u001b[39;00m partition.items():\n\u001b[32m      5\u001b[39m     G.nodes[node][\u001b[33m'\u001b[39m\u001b[33mcluster\u001b[39m\u001b[33m'\u001b[39m] = cluster\n",
      "\u001b[31mAttributeError\u001b[39m: module 'community' has no attribute 'best_partition'"
     ]
    }
   ],
   "source": [
    "# Cluster nodes using Louvain community detection (on undirected version)\n",
    "import community as community_louvain\n",
    "partition = community_louvain.best_partition(G.to_undirected()) if G.number_of_edges() > 0 else {}\n",
    "for node, cluster in partition.items():\n",
    "    G.nodes[node]['cluster'] = cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5883c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the labeled knowledge graph interactively with PyVis (edge labels, clusters)\n",
    "from pyvis.network import Network\n",
    "import random\n",
    "\n",
    "net = Network(height='900px', width='100%', notebook=True, bgcolor='#ffffff', font_color='black', directed=True)\n",
    "net.barnes_hut()\n",
    "\n",
    "cluster_colors = {}\n",
    "for node in G.nodes():\n",
    "    cluster = G.nodes[node].get('cluster', 0)\n",
    "    if cluster not in cluster_colors:\n",
    "        cluster_colors[cluster] = f\"#{random.randint(0, 0xFFFFFF):06x}\"\n",
    "    net.add_node(node, label=node, size=30, font={\"size\": 28}, color=cluster_colors[cluster])\n",
    "for source, target, data in G.edges(data=True):\n",
    "    label = data.get('label', '')\n",
    "    net.add_edge(source, target, title=label, label=label)\n",
    "\n",
    "net.set_options('''\n",
    "var options = {\n",
    "  \"nodes\": {\n",
    "    \"font\": {\"size\": 28},\n",
    "    \"size\": 30\n",
    "  },\n",
    "  \"edges\": {\n",
    "    \"color\": {\"inherit\": true},\n",
    "    \"smooth\": false,\n",
    "    \"arrows\": {\"to\": {\"enabled\": true}}\n",
    "  },\n",
    "  \"physics\": {\n",
    "    \"barnesHut\": {\n",
    "      \"gravitationalConstant\": -20000,\n",
    "      \"centralGravity\": 0.5,\n",
    "      \"springLength\": 150,\n",
    "      \"springConstant\": 0.04,\n",
    "      \"damping\": 0.09,\n",
    "      \"avoidOverlap\": 1\n",
    "    },\n",
    "    \"minVelocity\": 0.75\n",
    "  }\n",
    "}\n",
    "''')\n",
    "\n",
    "output_path = 'knowledge_graph.html'\n",
    "net.show(output_path)\n",
    "print(f\"Interactive knowledge graph saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
